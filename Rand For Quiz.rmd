```{r, include = FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
library(VIM) #visualizing missingness
library(ranger) #for random forests
library(skimr)
library(vip)
```

# Load data from the drug_data.csv file.  
```{r}
drug = read_csv("drug_data.csv")
```

```{r}
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity",
"Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive",
"SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis",
"Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh",
"LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
```

```{r data modification}
drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```

```{r mutate}
drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54", "55_64", "65_"))) %>%
mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18", "SomeCollege","ProfessionalCert", "Bachelors", "Masters", "Doctorate"))) %>%
mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia", "Ireland","Canada","UK"))) %>%
mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White", "White/Black", "Other", "White/Asian", "Black/Asian"))) %>%
mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
select(-ID)
```

```{r}
str(drug_clean)
```

```{r}
drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))
```

Check for missing data 
```{r}
skim(drug_clean)
```
## Question 1: Check for missing data in our “drug_clean” dataframe. True/False: There is missingness in the dataset.
## False

# Now we'll split the data.  
```{r}
set.seed(1234) 
drug_clean_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_clean_split)
test = testing(drug_clean_split)
```

```{r}
nrow(train)
```
## Question 2: Split the dataset into training (70%) and testing (30%) sets. Use a set.seed of 1234. Stratify by the “Nicotine” variable. How many rows are in the training set?
## 1318

Visualization  
```{r}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
## Question 3: True/False: Individuals in the 18-24 age group are proportionally more likely to be Nicotine users than not.
##True

```{r}
p1 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Nscore, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Escore, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Oscore, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
```{r}
p1 = ggplot(train, aes(x = Ascore, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Cscore, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Impulsive, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = SS, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
## Question 4: True/False: Individuals with higher “Impulsive” scores more likely to be Nicotine users than not.
## True

Set up our folds for cross-validation  
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```

Random forest with an R-defined tuning grid (this model took about 5 minutes to run)
```{r}
train_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

train_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(train_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  train_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)
```

Look at parameter performance (borrowed from https://juliasilge.com/blog/sf-trees-random-tuning/)
```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
## Question 5: Visualize the relationships between parameters and performance metrics. The highest accuracy in this visualization is just greater than which value:
## B. 0.730

```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  train_wflow,
  best_rf
)

final_rf
```
```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)
```

Check out variable importance
```{r}
final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```
## Question 6: Use the best mtry and min_n values from Question 5 to finalize the workflow and fit the model to training set. Examine variable importance. Which variable is most important?
## D. SS

Predictions  
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
```

Confusion matrix
```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```
## Question 7: To four decimal places, what is the accuracy of your model on the training set?
## 0.9165

## Question 8: To four decimal places, what is the naive accuracy (training set)?
## 0.6707

Predictions on test
```{r}
testpredrf = predict(final_rf_fit, test)
head(testpredrf)
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```
## Question 9: To four decimal places, what is your model’s accuracy on the testing set?
## 0.6966

## Question 10: The difference in accuracy on the training and testing sets implies?
## B. Overfitting is likely occurring



















